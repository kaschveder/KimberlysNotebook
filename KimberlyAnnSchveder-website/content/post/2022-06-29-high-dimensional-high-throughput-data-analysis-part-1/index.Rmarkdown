---
title: "High Dimensional High Throughput Data Analysis part 1"
author: "Kimberly Schveder"
date: '2022-06-29'
output: pdf_document
categories:
- R
- statistics
- big data
tags: []
slug: high-dimensional-high-throughput-data-analysis-part-1
---
In Spring of 2020 I was finishing my last semester of my masters in statistics program. My colleagues and I did not get to continue to learn this subject material in the classroom due to the lock down for the COVID-19 pandemic in March. 

I have decided to re-post the notes I took from Dr. Datta's class on "High-Dimensional, High-Throughput Data Analysis" - an important topic for data scientists to learn of. It was a nice summary course of the masters in statistics program. I have written out my notes in a Word Doc below and will break them into a series of blog posts.

The class went over: 
- [x] Reviewing of univariate and multivariate linear regression. 
- [x] Multiple Hypotheses testing and multiplicity adjustment (family-wise error rate control for independent and dependent p-values, false discovery rate control, etc). 
- [x] High Dimensional data visualization. 
- [x] Dimension reduction methods (sufficiency and equivalence, principal components and principal components regression, penalized regression, sliced inverse regression, etc.)
- [x] Model selection and estimator selection (feature selection, cross-validation, complexity selection)
- [x] Machine learning methods (introduction to come classification techniques and clustering techniques)
- [x] Aggregation of estimators and classifiers (boosting, bagging, other ensemble methods)
- [x] Graphical and network models (random graphs, graphs as statistical models, Gaussian graphical models)

Our first lecture, we went over what was covered in the article "Challenges of Big Data analysis", by Fan, Jianqing et. al.  in the National Science Review 1:293-314, 2014, doi: 10.1093/nsr/nwt032. 

The highlights I have about this article are the following: 
- [x] Goals and challenges of analyzing big data and high dimensional data analysis are to develop effective methods that can predict accurately future observations and to gain insight to relationship(s) between the features and responses for science. 
- [x] Due to large sample size, big data gives rise to additional goals: to understand heterogeneity and commonality across different sub-populations. That is, big data gives promises for: 
- (i) exploring hidden structures of each sub-population of the data that is not feasible and might even be treated as 'outliers' and 
- (ii) extracting important common features across many sub-populations even when those are large individual variations.
- [x] However, with big data there can be big challenges to deal with. There are 3 main challenges: 
- (i) high dimensionality brings noise accumulation and spurious correlations and incidental homogeneity; 
- (ii) high dimensionality combined with large samples size creates issues such as heavy computational cost and algorithmic instability;
- (iii) the massive samples in Big Data are typically aggregated from multiple sources at different time points using different technologies. This creates issues of heterogeneity, experimental variations and statistical biases, and requires us to develop more adaptive and robust procedures. 



There are a variety of linear regression modeling that were covered in this class. Here, I summarize the basics.


**Part 1: Introduction and Regression Basics**
A simple linear regression model is defined as 

`$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$`

where i = 1, ..., n, 
`$x_i$` is fixed, `$\epsilon_i	\sim  N(0, \sigma^2)$`, `$y_i	\sim  N(\beta_0 + \beta_1 X_i, \sigma^2)$` (independently and identically normally distributed about the regression line equation). 

We can demonstrate a simple linear model by looking at the dataset cars programmed into Rstudio. What is the distance traveled in miles based on the speed of the car? 

```{r cars}
head(mtcars)
summary(mtcars)
fit <- lm(mpg ~ wt, data = mtcars)
fit
plot(mpg ~ wt, data = mtcars)
```
Diagnostics and multiple linear regression next.



The next blog post will contain information on the gist of multivariate statistical methods. 

**Coming up.....**

For a multivariate regression model is defined with matrices organizing the information, 
`$\underline{Y} = \begin{pmatrix}
    y_{1}\\
    ...\\
    y_{n}
  \end{pmatrix} = X_n \underline{\beta} + \underline{\epsilon_i} $`



